# Project-4-Entrepreneurism-Ethics-Group6

## 1: Ethical Business Plan

### 1.A. Company Name of Fictitious Company

**JobMatch AI**

JobMatch AI is a startup focused on creating a fair, transparent, and inclusive hiring platform. Our technology uses artificial intelligence to match job seekers with employers based on skills, qualifications, and experience — while removing personal identifiers such as name, gender, race, or age to mitigate bias and promote equitable opportunity.

---

### 1.B. Long-Term Vision Statement

#### 1.B.1 Goals

The primary goal of JobMatch AI is to eliminate unconscious bias in recruitment and give every qualified candidate a fair chance at employment. We aim to build a platform that becomes the industry standard for fair hiring practices globally. In the next five years, we want to integrate with at least 500 companies, help place over one million candidates into jobs, and improve workplace diversity metrics by measurable amounts.

#### 1.B.2 Idea Origination

This idea was born from personal experiences and observations of inequality in hiring. Several of our founding members have seen talented candidates overlooked because of gender, ethnicity, or simply the way their names appeared on a résumé. Inspired by coursework in AI ethics and industry reports on bias in recruitment, we decided to build a system that leverages machine learning for good — using technology not just for efficiency but for fairness.

#### 1.B.3 Purpose/Values/Mission

Our purpose is to make hiring fair and equitable for everyone. We value transparency, diversity, accountability, and privacy. Our mission is to create a recruitment platform that removes irrelevant barriers, empowers candidates, and helps employers build stronger, more diverse teams.

#### 1.B.4 Key Questions

* How can we ensure that AI reduces bias instead of amplifying it?
* How do we make sure our platform remains transparent and accountable to candidates and employers?
* What measurable impact can we have on workforce diversity in the next five years?

---

### 1.C. Strategy with Ethical Impacts AND Ethical Safeguards

Below are the primary OKRs (Objectives and Key Results) that will guide JobMatch AI over the next 3–5 years.

---

#### 0: Company Summary

JobMatch AI is a hiring platform that aims to make recruitment more fair and inclusive. Instead of employers judging applicants based on personal details like names, gender, or race, the platform focuses on skills and experiences. Computation happens mostly on cloud servers where the matching algorithm runs, while recruiters and candidates access the system through a web interface.

The main stakeholders are job seekers, employers, and the company itself. Job seekers want equal opportunities, employers want efficient hiring, and the company needs to balance both. Other stakeholders include advocacy groups interested in fair hiring and, in some cases, regulators who monitor discrimination and accessibility.

---

#### 1: OKR 1 — Ensuring Ethical and Legal Compliance

**Objective:** Build and maintain a legally and ethically compliant hiring system that protects user privacy and promotes fairness.

**Key Result:** Reduce algorithmic bias in hiring recommendations by at least **30 percent** during the first year through the use of explainable-AI tools and regular bias testing.

**Stakeholders:**

* **Job Seekers:** Diverse individuals who deserve unbiased evaluations.
* **Employers:** Organizations seeking efficient hiring while staying compliant with labor and privacy laws.
* **Regulatory Agencies:** Groups such as the EEOC or the European Data Protection Board overseeing fairness and transparency.
* **JobMatch AI Team:** Developers, legal advisors, and data scientists responsible for ethical system design.

This OKR benefits all stakeholders because fairness in hiring protects candidates, reduces legal risks for employers, reinforces regulatory trust, and strengthens JobMatch AI’s credibility.

---

### 2. Metrics and Experimentation

**Metric 1 – Algorithmic Fairness Rate (AFR)**
**Goal:** Measure bias reduction after fairness tools are applied.
**Experiment:** Analyze 1,000 anonymized candidate profiles across demographics before and after bias detection.
AFR = ((bias before − bias after)/bias before) × 100.
A 30% improvement = success.

---

**Metric 2 – Transparency Satisfaction Index (TSI)**
**Goal:** Determine user trust and understanding of the system.
**Experiment:** Survey 300 users (50% employers, 50% candidates).
Questions include clarity, fairness perception, and reuse intention.
Score of **8/10 average** or **80% satisfaction** = success.

---

**Metric 3 – Compliance Audit Pass Rate (CAPR)**
**Goal:** Pass quarterly independent audits with no major risks.
**Experiment:** External reviewers assess compliance with GDPR, CCPA, and EEOC rules.
A **100% pass rate** = success.

---

### 3. Ethical Impacts and Issues

Even with strong safeguards, ethical concerns remain. Algorithms may unintentionally learn biased patterns if historical data includes discrimination.
A real example is Amazon’s 2018 AI hiring tool, which began downgrading female candidates due to biased past data.

**Risk Table:**

| Stakeholder | Financial Risk | Privacy Risk | Conflict of Interest | Rights Risk |
| ----------- | -------------- | ------------ | -------------------- | ----------- |
| Job Seeker  | Low            | High         | Medium               | High        |
| Employer    | Medium         | Low          | Medium               | Medium      |
| JobMatch AI | High           | Medium       | High                 | Medium      |
| Regulators  | Low            | Low          | Medium               | Low         |

**Analysis:**

* Job seekers face high privacy and discrimination risk.
* Employers risk reputational harm.
* JobMatch AI risks financial and ethical failure.
* Regulators face public trust challenges.

---

### 4. Ethical Safeguards

To address these risks, JobMatch AI will implement:

1. **Independent Ethics Board** – Quarterly algorithm reviews and public reports.
   *Success Measure:* 100% CAPR.

2. **Balanced Data Collection** – Ensuring gender, age, and ethnic representation.
   *Success Measure:* 30% bias reduction.

3. **Explainable AI Interface** – A dashboard that clarifies why matches were made.
   *Success Measure:* TSI ≥ 80%.

4. **Privacy-by-Design Framework** – Encryption, limited retention, and explicit consent.
   *Success Measure:* Zero major breaches and >90% opt-in.

These safeguards align with the **ACM Code of Ethics** and global standards.

---

#### 2: OKR 2 (Nayef) — User-Friendly Interface & Accessibility  

**Objective:** Create a user-friendly interface that makes it easy for all candidates, regardless of age, background, or ability, to apply for jobs.  

**Key Result:** By the end of the first year, at least 85% of users in different demographic groups will say the platform was easy to use.  

This OKR matters most for candidates, since the interface can either help or block them from applying. Employers benefit when more people can apply without issues. The company gains trust if the design is seen as accessible and fair.  

**Metric(s) with Experimentation**  
To see if this OKR is successful, JobMatch AI can use surveys, usability testing, and simple accessibility checks.  

- **Metric 1: User Satisfaction Survey.** After applying, candidates answer:  
  - “On a scale of 1–10, how easy was it to complete your application?”  
  - “Did you run into problems while applying (Yes/No)?”  
  Success means an average of 8.5 or higher and at least 85% saying “No.”  
  *Experiment:* Invite 200–300 students and job seekers from different age groups and backgrounds to try applying for a sample job. Collect responses and check for differences between groups.  

- **Metric 2: Task Completion Rate.** How many users can apply without help.  
  *Experiment:* In a study, first-time users are given 20 minutes to apply. If 90% finish, the goal is met.  

- **Metric 3: Accessibility Check.** Test if the site works with basics like keyboard-only navigation and screen readers.  
  *Experiment:* Have 20 participants with different accessibility needs try using the platform, plus run it through free accessibility checkers online.  

**Ethical Impact(s)/Issue(s)**  
- Exclusion risk: If the design is tested mostly with young, tech-savvy people, older adults or people with disabilities might find it harder to use.  
- Privacy risk: Usability studies often ask for demographic information, which could make users feel uneasy if not handled carefully.  
- Conflict of interest: The company might prioritize speed or looks over fairness.  

This connects to Epic v. Apple (2021), where Apple controlled how apps were accessed on iPhones. Epic argued this limited user choice and harmed fairness. Similarly, if JobMatch AI designs its interface only around certain users, others may be left out, which is an ethical issue.  

**Expected Ethical Impact Risk Table**  

| Stakeholder | Financial Risk | Privacy Risk | Conflict of Interest | Rights Risk |
|-------------|----------------|--------------|----------------------|-------------|
| Candidate   | Low            | Mid          | Mid                  | High        |
| Employer    | Mid            | Low          | Mid                  | Mid         |
| Company     | High           | Mid          | High                 | Mid         |
| Regulators  | Low            | Low          | Mid                  | Low         |  

Candidates face the biggest risks: if the interface excludes them, it could violate their right to fair access. The company carries high risk too, since bad design could hurt its reputation and finances.  

**Ethical Safeguards**  
Several steps can lower these risks:  

- Test with diverse groups. Include older adults, first-time job seekers, and people with disabilities in usability testing. Student volunteers and advocacy groups could help recruit participants.  
- Simple privacy steps. Keep demographic questions optional and separate from test results. Only collect what’s needed for analysis.  
- Accessibility first. Use common guidelines like WCAG (many free resources exist online) and run the site through free checkers.  
- Independent feedback. Create a small advisory group of students, users, and community advocates to review usability reports each semester.  

These safeguards are realistic for a startup and can be measured by repeating surveys and tests. If satisfaction scores or completion rates drop, adjustments can be made before full release.  

---

#### 3: OKR 3 (John) — Transparency & Explainable AI  

**Objective:** Build transparency and accountability into the hiring process through explainable AI features.  

**Key Results:**  
- 100% of matches generated by the platform will include a human-readable explanation.  
- Conduct annual transparency reports made public on our website.  
- Increase recruiter trust score by 20% through surveys after explainability features launch.  

**Metric(s) with Experiment(s)**  
Metrics include transparency report readership, recruiter trust survey scores, and frequency of candidate inquiries requesting explanations (target: <5% unresolved inquiries). Experiments include usability studies to test clarity of explanations.  

**Ethical Impact(s)/Issue(s)**  
Opaque AI systems can create accountability gaps and perpetuate systemic discrimination without visibility. If candidates don’t understand why they were not matched, trust in the system will erode.  

**Ethical Safeguards**  
- We will adopt explainable AI frameworks and publish clear documentation of model decision-making.  
- We will include an appeals process for candidates.  
- We will commission external audits of system outputs.  

---

#### 4: OKR 4 (Monisha) — Establishing Partnerships & Trust  

**Objective:**  
Develop strong partnerships with employers, advocacy organizations, and educational institutions while building trust with both candidates and companies that use JobMatch AI. Trust is central to the adoption of AI-driven recruitment, since employers must believe the platform is reliable and unbiased, and candidates must feel their applications are treated fairly.  

**Key Result:**  
By the end of the second year, JobMatch AI will secure at least 50 partnerships with employers and advocacy groups, and reach a trust rating of 85% or higher among candidates and employers surveyed.  

This OKR matters because partnerships provide credibility, growth, and access to diverse hiring pools, while trust ensures that the platform’s ethical claims are believed and upheld. Without both, the company risks being dismissed as “just another hiring app” rather than a transformative solution to recruitment bias.  

**Metric(s) with Experimentation**  

To test whether this OKR is successful, JobMatch AI will use multiple methods:  

- **Metric 1: Employer Partnership Growth.**  
  Track the number of formal partnerships signed with companies, universities, and advocacy groups.  
  *Experiment:* Launch a pilot program offering discounted onboarding fees for the first 20 employers. Monitor adoption rates and feedback from HR departments to refine partnership terms.  

- **Metric 2: Candidate Trust Index.**  
  Run surveys asking candidates to rate their level of trust in JobMatch AI on a scale of 1–10.  
  Questions include: “Do you feel JobMatch AI treated your application fairly?” and “Would you recommend JobMatch AI to a friend?”  
  *Experiment:* Conduct focus groups with job seekers across different demographics. Compare trust scores between first-time users and repeat users to identify improvement areas.  

- **Metric 3: Employer Confidence Check.**  
  Employers will be surveyed quarterly on transparency, fairness, and efficiency of the hiring process.  
  *Experiment:* Provide employers with an anonymized hiring audit (showing how resumes are stripped of identifiers). Measure whether transparency increases employer confidence.  

- **Metric 4: Advocacy Group Endorsements.**  
  Count the number of public endorsements or collaborations from advocacy organizations (e.g., disability rights groups, diversity networks).  
  *Experiment:* Invite advocacy organizations to serve as beta testers and publish joint reports about platform fairness.  

**Ethical Impact(s)/Issue(s)**  

Several ethical challenges arise when establishing partnerships and trust:  

- **Bias in Partnerships:** If JobMatch AI partners mainly with large corporations, smaller businesses or nonprofits may be excluded.  
- **Trust and Transparency Risk:** If the platform is not transparent about how algorithms make decisions, both employers and candidates may distrust the system.  
- **Conflict of Interest:** Employers might pressure JobMatch AI to optimize for efficiency (filling roles quickly) over fairness.  
- **Privacy Concerns:** In building trust through audits and reporting, sensitive candidate or employer data may be exposed if not carefully anonymized.  

**Expected Ethical Impact Risk Table**  

| Stakeholder | Financial Risk | Privacy Risk | Conflict of Interest | Rights Risk |
|-------------|----------------|--------------|----------------------|-------------|
| Candidate   | Low            | Mid          | Mid                  | High        |
| Employer    | Mid            | Mid          | High                 | Mid         |
| Company     | High           | Mid          | High                 | Mid         |
| Regulators  | Low            | Low          | Mid                  | Low         |  

**Ethical Safeguards**  

To lower these risks, JobMatch AI will implement the following safeguards:  

- **Diverse Partnerships:** Proactively partner not only with large corporations but also with small businesses, nonprofits, and advocacy groups.  
- **Algorithmic Transparency:** Publish simplified audit reports explaining how applications are anonymized and matched.  
- **Data Privacy Protections:** Ensure that audits and trust reports anonymize candidate and employer data, following GDPR and CCPA best practices.  
- **Independent Advisory Board:** Include representatives from advocacy organizations, academia, and ethics experts to oversee partnerships.  
- **Regular Feedback Cycles:** Hold quarterly listening sessions with both candidates and employers to gather real-world trust concerns and adjust practices accordingly.  

These safeguards make trust-building measurable. If employer partnerships rise but trust scores drop, JobMatch AI will review safeguards before expanding further. By grounding partnerships in fairness and oversight, JobMatch AI can ensure that growth does not come at the cost of equity.  

---

### References  

- Epic Games, Inc. v. Apple Inc., 559 F. Supp. 3d 898 (N.D. Cal. 2021).  
- Lazar, J., Goldstein, D. F., & Taylor, A. (2017). *Ensuring Digital Accessibility through Process and Policy*. Morgan Kaufmann.  
- General Data Protection Regulation (GDPR).  
- California Consumer Privacy Act (CCPA).  
- Equal Employment Opportunity (EEO) laws.  
- EU AI Act.  
- JobMatch AI Internal Document (2025). *OKR 4: Establishing Partnerships & Trust*.  

---

## 2: Cultural Policy

### 2.A. Core Values

At the center of JobMatch AI are values that shape how we want people to see us and how we want to see ourselves. We want to be thought of as fair, honest, and approachable. The whole reason the company exists is because the founders noticed that hiring is often unfair, with bias creeping in even when people don’t mean for it to. So, the first and most important value is fairness. Every design choice and every update to the system has to support equal opportunity.  

Transparency is another key value. People using the platform should not feel like they are handing their future over to a mysterious machine. We believe that candidates and employers deserve to know why certain matches are made. Inclusivity is also central, meaning that our platform should welcome people of different ages, abilities, and backgrounds. We also hold on to accountability, which is about taking responsibility when mistakes happen and showing that we are willing to improve. Lastly, privacy matters deeply because users trust us with sensitive data, and without that trust the company has no foundation. These values are not just abstract words, but practical guides for how we want to work and how we want others to think of us.  

### 2.B. Motivation

The culture we want in our company comes from both what excites us and what worries us. What we love is the possibility of using technology to level the playing field. It feels rewarding to think about a student, or someone changing careers, finally getting noticed for their skills instead of being judged by their name or background. We also love the idea that a small group of people can push back against a problem as big as hiring discrimination, and that gives our work a strong sense of meaning.  

What we fear is falling into the same patterns as other tech companies that start out with good intentions but later become detached from the people they were supposed to help. We fear the platform unintentionally reinforcing bias instead of reducing it, which is why we are careful about testing and feedback. Another fear is losing credibility. If people stop trusting that our system is fair, then everything we have built loses its purpose. These fears are not paralyzing, but they do keep us cautious, and that caution is part of the culture we want to preserve.  

### 2.C. Summary

Fair, open, inclusive, accountable, mindful.  

---

## 3: Ethics Policy

### 3.A. Core Items

JobMatch AI’s Ethics Policy is built on five main parts: **Fairness, Transparency, Accountability, Privacy, and Human Oversight.** These guide how our platform is made, how data is handled, and how decisions are made. Each one is a basic rule for running the company the right way.

**1. Fairness**  
Fairness is at the heart of our company. Every algorithm and design choice has to make sure all candidates are treated equally, no matter their gender, race, age, or background. We do regular **bias checks** with both our own tools and outside reviewers to look for unfair patterns in how candidates are matched. If bias is found, the model is fixed and tested again before we use it. Fairness also means being fair in business. Our partnerships and pricing are made to work for small businesses and nonprofits, not just big companies.

**2. Transparency**  
We believe that AI systems should be clear and easy to understand. Every job match from JobMatch AI includes a short, plain-language explanation of how it was made. We also publish yearly **Ethical Transparency Reports** that explain how data is used, what changes we made to our algorithms, and what we learned from audits and user feedback. By being open about both what works and what doesn’t, we earn people’s trust.

**3. Accountability**  
When we make mistakes, we admit them. The company’s **Ethics Review Committee** can pause or change any feature that raises an ethical concern. Users can appeal job-matching results or report problems directly. Each case is reviewed by a small team of people who understand data, ethics, and hiring. Accountability also means our leaders take responsibility. Every executive and board member goes through yearly ethics training and signs a pledge to follow our values.

**4. Privacy**  
We know that users trust us with personal data, and keeping it safe is our duty. JobMatch AI follows all major privacy laws, including **GDPR**, **CCPA**, and the new **EU AI Act**. Data is made anonymous before use, stored safely with encryption, and deleted after a set time. We never sell or share user data for other uses. A **Data Protection Officer (DPO)** checks all data handling every three months, and outside experts confirm that our rules are followed.

**5. Human Oversight and Doing Good**  
AI should help people make decisions, not replace them. Recruiters always make the final call in hiring, and no one is rejected by the system without a person checking it first. We also focus on **doing good** by making sure our technology helps society. Our project *JobMatch for All* gives free platform access to nonprofits that help people get back into work or learn new job skills.

These five parts work together to make sure JobMatch AI is both smart and fair. Ethics is part of every stage of our work — from design to testing to partnerships — so fairness is built in, not added later.

---

### 3.B. Board

The **Ethics and Technology Advisory Board** helps guide JobMatch AI and keep it responsible. It includes three well-known people whose experience in tech and ethics connects directly to what we do.

**1. Ryan Roslansky — CEO of LinkedIn**  
Ryan Roslansky has led LinkedIn since 2020. He has focused on skills-based hiring and giving everyone fair access to opportunities. Under his leadership, LinkedIn has made progress in using AI responsibly and improving fairness in hiring. We chose Roslansky because he understands how large tech platforms can affect people’s careers. His experience with trust, transparency, and ethical data use will help JobMatch AI grow responsibly.

**2. Dr. Timnit Gebru — Founder and Executive Director, Distributed AI Research Institute (DAIR)**  
Dr. Gebru is one of the best-known experts in AI ethics and fairness. She used to work at Google and helped write some of the most important research about bias in AI. She started her own research group to study how AI affects real people, especially those who are often left out. We chose Dr. Gebru because her work directly supports our goal of making AI fair and open. She will help guide our testing for bias and make sure our system treats everyone equally.

**3. Brad Smith — Vice Chair and President of Microsoft**  
Brad Smith is a long-time leader in tech ethics and law. He has spent years working on privacy, responsible AI, and digital rights at Microsoft. We chose him because he understands how to build tech that follows the law and protects people’s rights. His knowledge of global policy will help us keep JobMatch AI safe, legal, and fair for everyone.

**Why These Members Matter**  
Together, these three members bring a mix of leadership, research, and policy experience. Roslansky adds business and hiring knowledge, Gebru brings deep ethics and fairness research, and Smith adds global legal and policy experience. They meet every few months to review audits and give advice. Their feedback is shared in our yearly ethics report to keep JobMatch AI honest and open.

---
